{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c46c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install openslide\n",
    "!apt update && apt install -y openslide-tools\n",
    "!pip install openslide-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4a03a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#sklearn data split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as D\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10f72ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10611</th>\n",
       "      <td>ffd2841373b39792ab0c84cccd066e31</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10612</th>\n",
       "      <td>ffdc59cd580a1468eac0e6a32dd1ff2d</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>4+5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10613</th>\n",
       "      <td>ffe06afd66a93258f8fabdef6044e181</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10614</th>\n",
       "      <td>ffe236a25d4cbed59438220799920749</td>\n",
       "      <td>radboud</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10615</th>\n",
       "      <td>ffe9bcababc858e04840669e788065a1</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10616 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_id data_provider  isup_grade  \\\n",
       "0      0005f7aaab2800f6170c399693a96917    karolinska           0   \n",
       "1      000920ad0b612851f8e01bcc880d9b3d    karolinska           0   \n",
       "2      0018ae58b01bdadc8e347995b69f99aa       radboud           4   \n",
       "3      001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4   \n",
       "4      001d865e65ef5d2579c190a0e0350d8f    karolinska           0   \n",
       "...                                 ...           ...         ...   \n",
       "10611  ffd2841373b39792ab0c84cccd066e31       radboud           0   \n",
       "10612  ffdc59cd580a1468eac0e6a32dd1ff2d       radboud           5   \n",
       "10613  ffe06afd66a93258f8fabdef6044e181       radboud           0   \n",
       "10614  ffe236a25d4cbed59438220799920749       radboud           2   \n",
       "10615  ffe9bcababc858e04840669e788065a1       radboud           4   \n",
       "\n",
       "      gleason_score  \n",
       "0               0+0  \n",
       "1               0+0  \n",
       "2               4+4  \n",
       "3               4+4  \n",
       "4               0+0  \n",
       "...             ...  \n",
       "10611      negative  \n",
       "10612           4+5  \n",
       "10613      negative  \n",
       "10614           3+4  \n",
       "10615           4+4  \n",
       "\n",
       "[10616 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check train.csv\n",
    "Dataset = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset is too small (consider only split train dataset to(training:60%,testing:20%,validation:20%))\n",
    "testDataset = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\n",
    "testDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if dataset contains any null value (no null value)\n",
    "Dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#visualize gleason score data\n",
    "glsply = sns.countplot(x='gleason_score',data=Dataset,color='dodgerblue') \n",
    "glsply.set(xlabel = None)\n",
    "glsply.set(title='gleason score')\n",
    "glsply.tick_params(axis='x', rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many classes are in isUp grade(6 classes)\n",
    "isUp_grade= Dataset.isup_grade.unique()\n",
    "print('Classes in isUp grade: ',len(isUp_grade),'\\n')\n",
    "print(Dataset.isup_grade.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af11338",
   "metadata": {},
   "outputs": [],
   "source": [
    "glsply = sns.countplot(x='isup_grade',data=Dataset,color='green') \n",
    "glsply.set(xlabel = None)\n",
    "glsply.set(title='isUp grade')\n",
    "#glsply.tick_params(axis='x', rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glsply = sns.countplot(x='data_provider',data=Dataset) \n",
    "glsply.set(xlabel = None)\n",
    "glsply.set(title='Data Provider')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e285f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "check what is gleason score when isUp grade is 0 \n",
    "(when isUpgrade == 2, 4+3 maybe a misdiagnosis)\n",
    "(to see if we need to remove it)\n",
    "'''\n",
    "for i in range(6):\n",
    "    print('isUp grade = '+str(i)+': ')\n",
    "    print(Dataset.loc[Dataset.isup_grade == i,'gleason_score'].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e28890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adcbbdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in gleason score:  11 \n",
      "\n",
      "3+3         2666\n",
      "0+0         1925\n",
      "3+4         1342\n",
      "4+3         1243\n",
      "4+4         1126\n",
      "negative     967\n",
      "4+5          849\n",
      "5+4          248\n",
      "5+5          127\n",
      "3+5           80\n",
      "5+3           43\n",
      "Name: gleason_score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check how many classes are in gleason score (11 classes)\n",
    "gleason_score = Dataset.gleason_score.unique()\n",
    "print('Classes in gleason score: ',len(gleason_score),'\\n')\n",
    "print(Dataset.gleason_score.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many cases are in dataset\n",
    "print('Number of cases: ',len(Dataset))\n",
    "#check how many images are in train_image and train_label_masks folder\n",
    "train_path = '../input/prostate-cancer-grade-assessment/train_images'\n",
    "mask_path = '../input/prostate-cancer-grade-assessment/train_label_masks'\n",
    "\n",
    "train_image = 0\n",
    "for path in os.listdir(train_path):\n",
    "    if os.path.isfile(os.path.join(train_path, path)):\n",
    "        train_image += 1\n",
    "print('Number of train image: ',train_image)\n",
    "\n",
    "mask_image = 0\n",
    "for path in os.listdir(mask_path):\n",
    "    if os.path.isfile(os.path.join(mask_path, path)):\n",
    "        mask_image += 1\n",
    "print('Number of mask image: ',mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7825be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check some images\n",
    "#1.select 2 cases per gleason score class\n",
    "TempImageDataset = pd.DataFrame()\n",
    "for i in range(len(gleason_score)):\n",
    "    TempImageDataset = TempImageDataset.append(Dataset.loc[Dataset.gleason_score == gleason_score[i]][:2])\n",
    "TempImageDataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54499d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check images using openslide\n",
    "def plotImageAndmasks(TempImageDataset):\n",
    "    fig = plt.figure(figsize=(40, 70))\n",
    "    rows = 11\n",
    "    columns = 4\n",
    "    k = 1\n",
    "    for i in range(len(TempImageDataset)):\n",
    "        #get each image id\n",
    "        image_id = TempImageDataset.iloc[i]['image_id']\n",
    "        #read image\n",
    "        img = openslide.OpenSlide('../input/prostate-cancer-grade-assessment/train_images/'+str(image_id)+'.tiff')\n",
    "        #print('Number of image levels: ',img.level_count)#----3\n",
    "        #print('dimensions of levels: ',img.level_dimensions)#----((27648, 29440), (6912, 7360), (1728, 1840))\n",
    "        img = img.read_region((0, 0), img.level_count-1, img.level_dimensions[2]).convert('RGB')\n",
    "        fig.add_subplot(rows, columns, k)\n",
    "        #plt.axis('off')\n",
    "        plt.title('isUp_grade: '+str(TempImageDataset.iloc[i]['isup_grade'])+\n",
    "                  ' gleason_score: '+str(TempImageDataset.iloc[i]['gleason_score'])+\n",
    "                  '\\ndata_provider: '+str(TempImageDataset.iloc[i]['data_provider']))\n",
    "        k+=1\n",
    "        plt.imshow(img)\n",
    "        # plot corresponding masks\n",
    "        #1.check if it's in mask folder\n",
    "        file_exists = os.path.exists('../input/prostate-cancer-grade-assessment/train_label_masks/'+str(image_id)+'_mask.tiff')\n",
    "        if file_exists == True:\n",
    "            #2.load masks\n",
    "            mask = openslide.OpenSlide('../input/prostate-cancer-grade-assessment/train_label_masks/'+str(image_id)+'_mask.tiff')\n",
    "            mask_img = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[mask.level_count - 1]).convert(mode='RGB')\n",
    "            #split image to individual bands(a copy of one of original bands (red,green,blue))\n",
    "            #now mask is in red band.\n",
    "            mask_img = mask_img.split()[0]\n",
    "            #if the raw mode is “RGB”, then palette sequence must contain at most 768 values\n",
    "            palette = [0, 0, 0, 102, 102, 102, 255, 0, 0, 0, 251, 255, 246, 255, 0, 0, 255, 8]\n",
    "            palette.extend([0]*750)\n",
    "            mask_img.putpalette(data=palette, rawmode='RGB')\n",
    "            fig.add_subplot(rows, columns, k)\n",
    "            #plt.axis('off')\n",
    "            plt.title('isUp_grade: '+str(TempImageDataset.iloc[i]['isup_grade'])+\n",
    "                      ' gleason_score: '+str(TempImageDataset.iloc[i]['gleason_score'])+\n",
    "                      '\\ndata_provider: '+str(TempImageDataset.iloc[i]['data_provider']))\n",
    "            plt.imshow(mask_img)\n",
    "        k+=1\n",
    "\n",
    "plotImageAndmasks(TempImageDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ddf6620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10611</th>\n",
       "      <td>ffd2841373b39792ab0c84cccd066e31</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10612</th>\n",
       "      <td>ffdc59cd580a1468eac0e6a32dd1ff2d</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>4+5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10613</th>\n",
       "      <td>ffe06afd66a93258f8fabdef6044e181</td>\n",
       "      <td>radboud</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10614</th>\n",
       "      <td>ffe236a25d4cbed59438220799920749</td>\n",
       "      <td>radboud</td>\n",
       "      <td>2</td>\n",
       "      <td>3+4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10615</th>\n",
       "      <td>ffe9bcababc858e04840669e788065a1</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10616 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_id data_provider  isup_grade  \\\n",
       "0      0005f7aaab2800f6170c399693a96917    karolinska           0   \n",
       "1      000920ad0b612851f8e01bcc880d9b3d    karolinska           0   \n",
       "2      0018ae58b01bdadc8e347995b69f99aa       radboud           4   \n",
       "3      001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4   \n",
       "4      001d865e65ef5d2579c190a0e0350d8f    karolinska           0   \n",
       "...                                 ...           ...         ...   \n",
       "10611  ffd2841373b39792ab0c84cccd066e31       radboud           0   \n",
       "10612  ffdc59cd580a1468eac0e6a32dd1ff2d       radboud           5   \n",
       "10613  ffe06afd66a93258f8fabdef6044e181       radboud           0   \n",
       "10614  ffe236a25d4cbed59438220799920749       radboud           2   \n",
       "10615  ffe9bcababc858e04840669e788065a1       radboud           4   \n",
       "\n",
       "      gleason_score  target  \n",
       "0               0+0       0  \n",
       "1               0+0       0  \n",
       "2               4+4       4  \n",
       "3               4+4       4  \n",
       "4               0+0       0  \n",
       "...             ...     ...  \n",
       "10611      negative       0  \n",
       "10612           4+5       7  \n",
       "10613      negative       0  \n",
       "10614           3+4       2  \n",
       "10615           4+4       4  \n",
       "\n",
       "[10616 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relabel gleason score\n",
    "target = []\n",
    "for i in range(len(Dataset)):\n",
    "    if Dataset.iloc[i]['gleason_score'] == '0+0':\n",
    "        target.append(0)\n",
    "    if Dataset.iloc[i]['gleason_score'] == 'negative':\n",
    "        target.append(0)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '3+3':\n",
    "        target.append(1)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '3+4':\n",
    "        target.append(2)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '4+3':\n",
    "        target.append(3)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '4+4':\n",
    "        target.append(4)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '3+5':\n",
    "        target.append(5)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '5+3':\n",
    "        target.append(6)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '4+5':\n",
    "        target.append(7)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '5+4':\n",
    "        target.append(8)\n",
    "    elif Dataset.iloc[i]['gleason_score'] == '5+5':\n",
    "        target.append(9)\n",
    "\n",
    "Dataset['target'] = target\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba389c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.drop([Dataset.index[7273]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6b0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = Dataset['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77945f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2892\n",
      "num of img:  2892\n",
      "1126\n",
      "num of img:  1126\n",
      "2666\n",
      "num of img:  2666\n",
      "1242\n",
      "num of img:  1242\n",
      "849\n",
      "num of img:  849\n",
      "1342\n",
      "num of img:  1342\n",
      "248\n",
      "num of img:  248\n",
      "127\n",
      "num of img:  127\n",
      "43\n",
      "num of img:  43\n",
      "80\n",
      "num of img:  80\n",
      "Image Copy Finished\n"
     ]
    }
   ],
   "source": [
    "#copy images to corresponded folders\n",
    "def prepareImageFolder(tgt,Dataset):\n",
    "    #create data folder\n",
    "    datapath = '{}'.format('data')\n",
    "    if not os.path.exists(datapath):\n",
    "        os.makedirs(datapath)\n",
    "\n",
    "    for ttype in tgt:\n",
    "        newpath = 'data/{}_img'.format(ttype)\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "\n",
    "    for ttype in tgt:\n",
    "        image = Dataset.loc[Dataset.target == ttype,'image_id'].to_list()\n",
    "        print(len(image))\n",
    "        count = 0\n",
    "        for img in image:\n",
    "            imagefile = str(img)+'.png'\n",
    "            #check image path\n",
    "            for root, dirs, files in os.walk('archive/train_images/train_images'):\n",
    "                for name in files:\n",
    "                    if name == imagefile:  \n",
    "                        imagepath = os.path.abspath(os.path.join(root, name))\n",
    "\n",
    "            shutil.copy(imagepath, 'data/'+str(ttype)+'_img/')\n",
    "            count +=1\n",
    "        print('num of img: ', count)\n",
    "    print('Image Copy Finished')\n",
    "\n",
    "prepareImageFolder(tgt,Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cf1f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of data label:  10615\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getcwd() + \"/data\"\n",
    "#preprocess dataset\n",
    "def checkDataLabel(data_dir):\n",
    "    dataset = torchvision.datasets.ImageFolder(root= data_dir)\n",
    "    label = []\n",
    "    for data in dataset.samples:\n",
    "        label.append(data[1])\n",
    "    return label\n",
    "\n",
    "data_label = checkDataLabel(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d154b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 6793\n",
      "Test Size: 2123\n",
      "Val Size: 1699\n"
     ]
    }
   ],
   "source": [
    "#split dataset (train dataset 60%, test dataset 20%, val dataset 20%)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torch\n",
    "\n",
    "########tutorial: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html########################\n",
    "def ShuffleSplit(data):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "    X,Y = data.numpy(),data.numpy()\n",
    "    split.get_n_splits(X, Y)\n",
    "    train_data, test_data= next(split.split(X, Y))\n",
    "    return train_data, test_data\n",
    "\n",
    "def splitData(data_label):\n",
    "    #split data train data:60%, test data:20% and val data:20%\n",
    "    trainANDval_data,test_data = ShuffleSplit(torch.FloatTensor(data_label))\n",
    "    #delete test data from data pool\n",
    "    train_label = np.delete(data_label, test_data, None)\n",
    "    train_data, val_data = ShuffleSplit(torch.FloatTensor(train_label))\n",
    "    \n",
    "    return train_data,test_data,val_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2927a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 63.99434762129063 %\n",
      "Test Size: 20.0 %\n",
      "Val Size: 16.005652378709375 %\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data,val_data = splitData(data_label)\n",
    "\n",
    "print(\"Train Size:\", train_data.shape[-1]/len(data_label)*100,'%')\n",
    "print(\"Test Size:\", test_data.shape[-1]/len(data_label)*100,'%')\n",
    "print(\"Val Size:\", val_data.shape[-1]/len(data_label)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bf8fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image transformations\n",
    "norm_mean = (0.4914, 0.4822, 0.4465)\n",
    "norm_std = (0.2023, 0.1994, 0.2010)\n",
    "def transformation(data):\n",
    "    if data == 'train':\n",
    "        transform = torchvision.transforms.Compose([transforms.Resize((224,224)),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.RandomRotation(degrees=60),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(norm_mean, norm_std)])\n",
    "    elif data == 'test':\n",
    "        transform = torchvision.transforms.Compose([\n",
    "                        transforms.Resize((224,224)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(norm_mean, norm_std)])\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data function\n",
    "\n",
    "def loadData(data_dir):\n",
    "    #load data\n",
    "    dataset = torchvision.datasets.ImageFolder(root= data_dir, transform=transformation('train'))\n",
    "    train = torch.utils.data.sampler.SubsetRandomSampler(train_data)\n",
    "    #load dataset to memory\n",
    "    train_data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False,num_workers=1, sampler= train)\n",
    "\n",
    "    #load data\n",
    "    dataset = torchvision.datasets.ImageFolder(root= data_dir, transform=transformation('test'))\n",
    "    val = torch.utils.data.sampler.SubsetRandomSampler(val_data)\n",
    "    #load dataset to memory\n",
    "    validation_data_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=False, sampler=val)\n",
    "\n",
    "    #load data\n",
    "    dataset = torchvision.datasets.ImageFolder(root= data_dir, transform=transformation('test'))\n",
    "    #load dataset to memory\n",
    "    test = torch.utils.data.sampler.SubsetRandomSampler(test_data)\n",
    "    test_data_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=False, sampler=test)\n",
    "      \n",
    "    return train_data_loader,validation_data_loader,test_data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af61209",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader,validation_data_loader,test_data_loader = loadData(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcdff887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "417b627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/miccai-educational-initiative/skin-cancer-image-classification-an-educational-guide-2a043a1beb59\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(3, 6, (5,5), padding=2),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d((2, 2)))\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.seq = nn.Sequential(\n",
    "                nn.Linear(16*54*54, 120),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(120, 84),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(84, 10)\n",
    "                )\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.nn.functional.max_pool2d(torch.nn.functional.relu(self.conv2(x)), (2,2))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.seq(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b05f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model to device\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05ffae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "train loss: 1.558  train accuracy:0.323  val loss: 1.439  val accuracy: 0.345 \n",
      "Epoch: 2\n",
      "train loss: 1.444  train accuracy:0.327  val loss: 1.442  val accuracy: 0.310 \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "#for accuracy and losses record\n",
    "train_accuracy = []\n",
    "Val_accuracy = []\n",
    "train_losses = []\n",
    "Val_losses = []\n",
    "\n",
    "#start training\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    correct_total= 0.0\n",
    "    Vcorrect_total= 0.0\n",
    "    num_samples_total=0.0\n",
    "    Vnum_samples_total=0.0\n",
    "    valid_loss = 0.0\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # parameter gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        #accuracy for it\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        num_samples_total +=labels.size(0)\n",
    "        correct_total +=correct\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(train_loss/len(train_data_loader))\n",
    "    train_accuracy.append(correct_total/num_samples_total)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for val_inputs, val_labels in validation_data_loader:\n",
    "        val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "        val_outputs = model(val_inputs)\n",
    "    \n",
    "        vloss = criterion(val_outputs, val_labels)\n",
    "        valid_loss += vloss.item() \n",
    "        _, Vpredicted = torch.max(val_outputs, 1)\n",
    "        Vcorrect = (Vpredicted == val_labels).sum().item()\n",
    "        Vnum_samples_total +=val_labels.size(0)\n",
    "        Vcorrect_total +=Vcorrect\n",
    "        \n",
    "\n",
    "    print('Epoch: %d' %(epoch+1))\n",
    "    print('train loss: %.3f  train accuracy:%.3f  val loss: %.3f  val accuracy: %.3f ' %(train_loss/len(train_data_loader), correct_total/num_samples_total,valid_loss/len(validation_data_loader),Vcorrect_total/Vnum_samples_total))\n",
    "\n",
    "    \n",
    "    Val_losses.append(valid_loss/len(validation_data_loader))\n",
    "    Val_accuracy.append(Vcorrect/Vnum_samples_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43f2b02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL EVALUATION\n",
    "\n",
    "plt.plot(train_accuracy, label='train_accuracy')\n",
    "plt.plot(Val_accuracy, label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('train_accuracy vs val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d890a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(Val_losses, label='valid_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs valid_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47e915bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradCam part(not finished)\n",
    "from collections import OrderedDict, Sequence\n",
    "\n",
    "class GradCAM():\n",
    "    def __init__(self, model):\n",
    "        super(GradCAM, self).__init__(model)\n",
    "        self.map = OrderedDict()\n",
    "        self.grad = OrderedDict()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        self.image_shape = image.shape[2:]\n",
    "        return super(GradCAM, self).forward(image)\n",
    "\n",
    "    def generate(self, target_layer):\n",
    "        if target_layer in self.map.keys():\n",
    "            maps = self.map[target_layer]\n",
    "        if target_layer in self.grad.keys():\n",
    "            grads = self.grad[target_layer]\n",
    "          \n",
    "        gcam = torch.mul(maps, weights).sum(dim=1, keepdim=True)\n",
    "        gcam = torch.nn.functional.relu(gcam)\n",
    "\n",
    "        gcam = torch.nn.functional.interpolate(gcam, self.image_shape, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        return gcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4dfe53b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Grad cam\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mplotGradCam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(image[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     35\u001b[0m image2  \u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mnumpy() \n",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36mplotGradCam\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Images\u001b[39;00m\n\u001b[1;32m     15\u001b[0m images \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m gcam \u001b[38;5;241m=\u001b[39m \u001b[43mGradCAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m probs, ids \u001b[38;5;241m=\u001b[39m gcam\u001b[38;5;241m.\u001b[39mforward(images)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_layer \u001b[38;5;129;01min\u001b[39;00m target_layers:\n\u001b[1;32m     20\u001b[0m      \u001b[38;5;66;03m# Grad-CAM\u001b[39;00m\n",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36mGradCAM.__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGradCAM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "#gradCam part(not finished)\n",
    "def plotGradCam(image, model):\n",
    "    # Model\n",
    "    model = model\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # The layers\n",
    "    target_layers = [\"conv2\"]\n",
    "    target_class = label\n",
    "\n",
    "    # Images\n",
    "    images = image.unsqueeze(0)\n",
    "    gcam = GradCAM(model=model)\n",
    "    probs, ids = gcam.forward(images)\n",
    "   \n",
    "    for target_layer in target_layers:\n",
    "         # Grad-CAM\n",
    "        regions = gcam.generate(target_layer=target_layer)\n",
    "        for j in range(len(images)):\n",
    "            gcam=regions[j, 0]\n",
    "            plt.imshow(gcam.cpu())\n",
    "            plt.show()\n",
    "            \n",
    "image, label = next(iter(validation_data_loader))\n",
    "# Load the model\n",
    "model = model\n",
    "# Grad cam\n",
    "plotGradCam(image[0].to(device), model)\n",
    "image = np.transpose(image[0], (1,2,0))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063f05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
